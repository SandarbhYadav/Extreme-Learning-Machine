{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "import zipfile\n",
    "import scipy.io as scio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing as ps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data\n",
    "with zipfile.ZipFile('diabetes.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "with zipfile.ZipFile('sinc.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = open('diabetes2.dt', 'r').read().splitlines()[7:]\n",
    "for i, r in enumerate(dat):\n",
    "    dat[i] = [float(v) for v in r.split(' ')]\n",
    "dat = np.array(dat)\n",
    "\n",
    "print(sum(dat[:,-1])/len(dat))\n",
    "print(len(dat))\n",
    "print(len(dat)*len(dat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train, test = train_test_split(dat, test_size = 0.1, random_state = 44)\n",
    "train_x, train_y = train[:, :-1], train[:, -1]\n",
    "test_x, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "\n",
    "print(sum(train_y)/len(train))\n",
    "print(len(train))\n",
    "print(sum(test_y)/len(test_y))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train_x)\n",
    "\n",
    "train_x_norm = scaler.transform(train_x)\n",
    "test_x_norm = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare architecture\n",
    "n = len(train_x_norm[0])\n",
    "m = len(train_x_norm)\n",
    "\n",
    "he = HeUniform(seed=43)\n",
    "model = Sequential([\n",
    "    Input(shape = (n,)),\n",
    "    \n",
    "    Dense(n*2, kernel_initializer=he),\n",
    "    LeakyReLU(),\n",
    "    \n",
    "    Dense(n*3, kernel_initializer=he),\n",
    "    LeakyReLU(),\n",
    "    \n",
    "    Dense(1, activation='sigmoid', kernel_initializer=HeUniform)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELM modification\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocastic Gradient descent for Online - ELM\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, shuffle=True, validation_split = 0.1, batch_size = 1, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_x_norm, train_y, batch_size = 1)\n",
    "model.evaluate(test_x_norm, test_y, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to single layer perceptron\n",
    "model = Sequential([\n",
    "    Input(shape=(n,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_norm, train_y, validation_split=0.1, batch_size = 1, epochs = 1)\n",
    "model.evaluate(train_x_norm, train_y)\n",
    "model.evaluate(test_x_norm, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
